<!-- START doctoc generated TOC please keep comment here to allow auto update -->
<!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->


- [進め方](#%E9%80%B2%E3%82%81%E6%96%B9)
- [5章 連語](#5%E7%AB%A0-%E9%80%A3%E8%AA%9E)
  - [5.1 頻度](#51-%E9%A0%BB%E5%BA%A6)
  - [5.2 平均と分散](#52-%E5%B9%B3%E5%9D%87%E3%81%A8%E5%88%86%E6%95%A3)
  - [5.3 仮設検定](#53-%E4%BB%AE%E8%A8%AD%E6%A4%9C%E5%AE%9A)
    - [5.3.1 t検定](#531-t%E6%A4%9C%E5%AE%9A)
    - [5.3.2 差の仮説検定](#532-%E5%B7%AE%E3%81%AE%E4%BB%AE%E8%AA%AC%E6%A4%9C%E5%AE%9A)
    - [5.3.3 Pearson のカイ二乗検定](#533-pearson-%E3%81%AE%E3%82%AB%E3%82%A4%E4%BA%8C%E4%B9%97%E6%A4%9C%E5%AE%9A)
  - [5.4 相互情報量](#54-%E7%9B%B8%E4%BA%92%E6%83%85%E5%A0%B1%E9%87%8F)
  - [5.5 連語とは何か](#55-%E9%80%A3%E8%AA%9E%E3%81%A8%E3%81%AF%E4%BD%95%E3%81%8B)
  - [5.6 さらに学ぶために](#56-%E3%81%95%E3%82%89%E3%81%AB%E5%AD%A6%E3%81%B6%E3%81%9F%E3%82%81%E3%81%AB)

<!-- END doctoc generated TOC please keep comment here to allow auto update -->

---
# 進め方
- 第１回目
    - 5.1
    - 5.2
    - 5.3 少し(t検定までいけたらラッキー)
- 第２回目
    - 5.3 残り
    - 5.4
    - 5.5
    - 5.6 (省略するかも)

# 5章 連語
- 連語(Collocation)とは、二つ以上の単語からなる慣用に従った物事の言い方
- 連語とは単語を習慣的(habitual)、あるいは慣習的(customary)にどう配置するかを述べたもの
    - ex) 名詞句：strong tea, weapons of mass destruction
    - ex) 句動詞(phrasal verb)：make up
    - ex) 決まり文句(stock phrase)：the rich and powerful
- 連語の特徴
    - 意味の構成性(compositionality)が限定的にしか成立しないこと
        - 構成性：その言語表現全体の意味が部分の意味から推測できること
    - 連語は、部分の意味を組み合わせたものに、通常何らかの意味が追加される点で、「完全に構成的」とは言えない
    - ex) strong tea
        - strong: この例では、「豊富な活性成分を持っている」の意
        - これは、「大きな物理的な力を持っている」という、strong 自体の基本的な意味と密接に関係しているが微妙に異なる
    - イディオム: 非構成的な表現の最も極端な例
        - ex) kick the bucket: くたばる
        - ex) to hear it through the grapevine: 風のたよりに聞く
        - 間接的で歴史的な関係を持つだけ
        - バケツ(bucket)やブドウのつる(grapevine)の話はしていない
        - 連語の多くは、ここまで非構成的ではない
- 連語とかなり重なる概念
    - 用語(term)
    - 専門用語(technical term)
    - 専門用語句(terminological phrase)
    - これらは、専門用語抽出(terminology extraction) という処理によって抽出される連語
- 連語の応用分野
    - 自然言語生成: 出力を自然にする(powerful tea, to take a decision という誤りを避ける)
    - 計算論的辞書編纂(へんさん)学: 辞書に掲載すべき重要な連語を自動選定
    - 構文解析: 解析結果が曖昧なとき自然な連語を選ぶ
    - コーパス言語研究: ex) 言語を通して文化的なステレオタイプの強化が起こるといった社会現象の研究
- 意味の文脈理論(Contextual Theory of Meaning)
    - 文脈の重要性を説いている理論
    - 架空の理想的な話者ではなく、どういう社会的な設定のもとで発話されているか
    - 孤立した文ではなく、会話、テキストにおいて、前後にどういう文が存在するか
    - 連語(周辺の単語の作る文脈の重要性)
    - ファースの有名な格言: 「単語は何を連れとしているかで特徴付けられる」
    - これらの文脈特徴は、構造主義言語学において、典型的な扱いによって簡単に失われる
- 言語の文脈的な見方
    - strong tea と powerful tea
    - 英語では、powerful tea と言わず、strong tea という
    - 構造的な性質からは、何もわからない
    - powerful: ヘロインのような薬を形容するが、タバコや紅茶、コーヒーを形容するのには使わない
- 連語を見つける手法
    - 頻度による選択(5.1)
    - 単語とその共起語の間の距離の平均と分散に基づく選択(5.2)
    - 仮説検定(5.3)
    - 相互情報量(5.4)
    - 「連語」とは何かという問題に立ち戻る(5.5)
        - 提案されているさまざまな定義
        - あるフレーズが連語かどうかをテストする方法

## 5.1 頻度
- テキストコーパス中の連語を見つける一番簡単な方法は、単語の出現頻度を数えること
- 二つの単語が何回も一緒に出現する
    - 二単語の組が単なる組み合わせによる機能ではうまく説明できない特別な機能を持っている
- 表5.1: コーパス中のバイグラム(隣り合う2語)の高頻度順
    - 「New York」以外は、機能語(function word)の組
- 単純なヒューリスティックで相当改善可能
    - 句になりそうな品詞のパターンだけを通すようにフィルタをかける

        **表5.2**

        | 品詞パターン | 例 |
        ---------------| ---------- |
        | A N | linear function
        | N N | regression coefficients
        | A A N | Gaussian random variable |
        | A N N | cumulative distribution function |
        | N A N | mean squared error |
        | N N N | class probability function |
        | N P N | degrees of freedom |

   - A: 形容詞、P: 前置詞、N: 名詞

- 表5.3: 表5.2 のフィルタを通したフレーズの高頻度順
   - 非構成的ではないフレーズは、３つのみ
       - last year, last week, first time(表5.3 には存在しない)
   - 「York City」: 実装誤りにより抽出された
- 表5.4: 'poworful w'、'strong w' のパターンの高頻度順
   - まあまあ、いい結果の例
   - strong challenge, powerful computers は、正解
   - powerful challenge, strong computers は、正しくなさそうという根拠になりうる
   - 頻度に基づく方法の限界: man など、いずれの形容詞(strong, powerful)とも一緒に使われる単語がある
   - より洗練された分析が必要
- 以上は、単純な定量的方法(頻度による選択方法)がうまくいくことを示している
   - 以降は、「ストップ語リスト」(stop word list)を使う
   - ストップ語リスト: 最も頻度の高い品詞タグが動詞、名詞、形容詞であるような単語以外を排除するためのリスト
   - ただし、ストップ語リストは、紹介されていない様子

## 5.2 平均と分散
- 頻度に基づく方法は、固定的なフレーズを見つけるのにうまくいく
- 実際の連語を構成する二つの単語は、もっと柔軟な関係で並んでいることが多い
    - 頻度に基づく方法以外の方法が必要
- ex) (5.1) 動詞knock と最も頻繁にknock の項(argument)になるdoor の例
    - 「ドア(door)をノックする(knock)」という表現について
        - a. she knocked on his door
        - b. they knocked at the door
        - c. 100 women knocked on Donaldson's door
        - d. a man knocked on the metal front door
    - knock と door の間に現れる単語は、多様
    - knock と door の間の距離(たぶん、語数)も一定ではない
    - 固定的なフレーズに対する手法ではうまくいかないはず
    - これらの単語の出現パターンを見ると、「叩く」という状況を表現する適切な動詞は、knockっぽい
    - door に対しては、hit, beat, rap を使わないと判断するのに十分な規則性がある
- 固定的な連語と可変な連語
    - 簡単のため、本書のほとんどは、固定的な連語でしかもバイグラム(連続する2語)
    - 連続する2語に適用可能な方法を、連続しない2語の組に拡張する方法は、容易に考えられる
        - 連語のための「窓」(１つの単語の前後3, 4語の幅)を定める
        - 定めた窓の中のすべての2単語の組を連語関係を持つ拡張されたバイグラム(のリスト)に加える
        - この拡張されたバイグラムの集合を使って以降の処理を行う
- 平均と分散に基づく方法
    - 平均と分散の定義において二つの単語がどういう間隔で出現するかというパターンを考慮している
    - 2語間の間隔のパターンが比較的、予測可能であるならば、knock ... door という必ずしも固定的でない連語が存在する証拠が得られたことになる
        - 2語間の間隔の変動するパターンが予測可能ならば、予測された2語は、固定的でない連語だと解釈する
    - 連語とは何かというより深い議論はこの章の最後までおあずけ☆
    - コーパスにおいて、二つの間のオフセット(offset)(符号付き距離)の平均(mean)と分散(variance)を計算すること
        - ex) 5.1 の例で平均を説明

        <img src="https://latex.codecogs.com/gif.latex?mean&space;=&space;\frac{1}{4}(3&space;&plus;&space;3&space;&plus;&space;5&space;&plus;&space;5)&space;=&space;\frac{16}{4}&space;=&space;4.0">

    - この計算では、Donaldson's が、Donaldson, ', s という三つの単語に分解されるとみなしている
    - もし、door が knocked の前に出現した場合は、オフセットは負の数になる
        - ex) the door that she knocked on の場合は、オフセットは、-3
    - 本節では、knocked を中心に、前後9語の窓内の位置に限定して分析を行う
    - 分散(↓の定義は、不偏分散)は、個々のオフセットがどれだけ平均からばらついているかという尺度

        <img src="https://latex.codecogs.com/gif.latex?variance&space;=&space;s^2&space;=&space;\frac{\sum_{i=1}^{n}(d_i&space;-&space;\bar{d})^2}{n-1}">

    - 標本偏差(sample deviation) ... 不偏標準偏差のこと

        <img src="https://latex.codecogs.com/gif.latex?s&space;=&space;\sqrt{s^2}">

    - ex) 5.1 の例で標本偏差を説明

        <img src="https://latex.codecogs.com/gif.latex?s&space;=&space;\sqrt{&space;\frac{1}{3}(3-4.0)^2&space;&plus;&space;(3-4.0)^2&space;&plus;&space;(5-4.0)^2&space;&plus;&space;(5-4.0)^2&space;}&space;\approx&space;1.15">

    - 平均と標本偏差によって、コーパス中の二つの単語の距離の分布の特徴がわかる
        - 分布の特徴として、歪度(skewness/3次モーメント)、尖度(kurtosis/4次モーメント)もある
        - tips) 平均は、１次モーメント、分散は、2次モーメント
        - 標本偏差が小さい: 二つの単語がほとんど同じ相対位置で出現する
        - 標本偏差が0: 二つの単語が常に同じ相対位置で出現する
    - 図5.2 一番目の図の解説
        - 分布が示す情報は、ある語とほかの語との距離の分布のピークによっても説明できる
        - 「strong」の「opposition」からの距離の分布のピーク: -1
        - 「strong」の「opposition」に対する分散は小さい(_s_ = 0.67)
        - 平均が -1.15 であるので、「strong」が通常は、-1 の位置に出現することを示している
        - -4 の位置が1回出現したという事実をノイズとして扱っている点に注意
            - サンプル数が増えたら-4 の出現数を無視できないかもしれないということ
    - 2つの単語の関係を見る場合、位置0 の出現数は常に0(2単語のオフセットは、必ず1以上)
    - 図5.2 二番目の図の解説
        - 「support」に対する「strong」の位置の頻度分布の例 (_s_ = 1.07)
        - 一番目の図と同じように分析する
    - 図5.2 三番目の図の解説
        - 「for」に対する「strong」の位置の頻度分布の例
        - 先の二つの例に比べると比較的、一様に分布している例(一様分布とは言いがたい)
        - つまり、分散(不偏標準偏差)が大きい例(_s_ = 2.15)
    - 表5.5
        - 平均と分散による方法によって見つけられる連語の組の例
        - 真ん中の四つの例: 偏差が大きい →  二つの単語間に考慮すべき関係がないことを意味する
        - 一様分布に近い分布は、平均が0 に近い
        - 興味の対象は、少し離れた距離の頻度が大きいもの
- 以上で紹介した連語検出の方法は、Smadjaによるもの
    - 位置のヒストグラムにおいて、「平らな」ピークを除外
        - ex) 図5.2の strong / for の組み合わせで、-2 のところを除外
    - この除外が用語抽出において極めてうまくいくらしい(推定精度80%らしい)
    - Smadja の連語概念は、ほかのものより制約がゆるい
    - knocked / door の組み合わせは、テキスト生成には有用かもしれないが専門用語としての連語にはならなさそう
        - 平均と分散の方法も、汎用的ではない、と言いたいのかな？！
- 分散による連語の検出は、間に挿入される要素や相対位置が可変であるような単語の組み合わせを見つけたい場合に適切な方法
        - 平均と分散の方法は、特定の条件下で有用、と言いたいのかな？！

## 5.3 仮設検定
- これまでの手法の問題
    - 頻度が高いこと、分散が小さいことは、偶然起こりうる
    - ex) new campanies: 特に連語ではなくても、これら二つの単語がまったく偶然に何回も出現しうる
    - 二つの単語が偶然よりも頻繁に一緒に出現するかどうかを知りたい 
        -   これは、仮説検定を誘導するためのフリですね！
- 仮説検定
    - ある事柄が偶かどうかをみつもること
    - 統計学の古典的な問題
    - ベイズで代用する方法もあるらしい
        - ref) 「はじめての 統計データ分析 ―ベイズ的〈ポストp値時代〉の統計学」
- 我々の問題での仮説検定
    - 帰無仮説(null hypothesis): $H_0$
        - 二つの単語の間に偶然以上の結びつきがないこと
    - $H_0$を定式化
    - $H_0$が真であると仮定して二つの単語の共起が起こる確率$p$を計算する
    - $p$の値が十分小さい場合、「帰無仮説$H_0$を棄却する」と表現する
        - (慣例的には、0.05などを基準とする; この基準を「有意水準」(significance level)と呼ぶ)
        - 有意水準($\alpha$と書くことが多い)は、0.05, 0.01, 0.005, 0.001 などとすることが多い
    - $p$が十分小さくない場合、「帰無仮説$H_0$が成り立ちうる」と表現する(棄却できないともいう)
        - 「帰無仮説が棄却できない」ことと、「帰無仮説の否定」(対立仮説と呼ぶ)が成り立つとは言えない
        - 帰無仮説が棄却できない点は、帰無仮説と帰無仮説の否定(対立仮説)のいずれも成り立つ可能性がある点に注意
    - tips) 仮説検定では、本当は「帰無仮設を棄却したい」という文脈(心持ち)で行うケースが基本となっている(もちろん、そうでない場合もある)
- 仮説検定の定式化
    - 二つの単語が連語を形成しないという帰無仮説の定式化
    - 「連語を形成しない」を、「完全に独立」と考える/言い換えてみる
    - つまり、二つの単語$w^1 $、$w^2$の組について、その二語が互いに完全に独立に出現すると仮定する
    - この仮定のもとでは、二つの単語がこの順に連続して出現する確率は、次式で与えられる(独立の定義より)

        <img src="https://latex.codecogs.com/gif.latex?P(w^1&space;w^2)&space;=&space;P(w^1)&space;P(w^2)">

    - このモデルは、過度に単純化したモデル / 経験的にも正しくない
        - 独立してないもので、「連語を形成しない」組もある点に注意(先の「new campanies」がその代表)
    - しかし、当面の帰無仮説としてこの独立性を採用する

### 5.3.1 t検定
- 特定の2語の並びがどの程度起こりやすいか、起こりにくいかを評価する統計的検定手法
- 連語の発見のために広く使われている手法は、t検定
- t検定は、測定値の集合を１つのサンプル(標本)とし、平均、分散を調べる
    - 帰無仮説は、「このサンプルが平均μの分布から取り出されたものである」
    - 測定値の平均(標本平均)と予測される平均(母平均とみなす)との差をデータの分散によって調整した式(統計量)を用いる
    - 平均μの正規分布から取り出したと仮定した場合に、どの程度尤もらしいかを評価する
    - t統計量を次式で与える

        <img src="https://latex.codecogs.com/gif.latex?t&space;=&space;\frac{\bar{x}&space;-&space;\mu}{\sqrt{\frac{s^2&space;}{N}}}">

    - $\bar{x}$: 標本平均、$s^2 $: 標本分散、$N$: 標本サイズ(1標本の要素数)
    - t統計量が十分大きい → 帰無仮説を棄却
        - t分布表で判断(昔の方法)
        - 今は、RとかPython で簡易に算出可能
        - t統計量はあまりみない
        - 概ね、$p$値を見るだけで事足りることが多い
        - $p$値で判断する手法を単に使ってるだけともいう
    - tips)統計学者は、$p$値を絶対視することを嫌う
        - ちゃんと、可視化した上で検定しなさいということ
        - ただ、t検定に限れば、正規性に頑健性があるので、たぶん大丈夫
        - 気になる人は、ウィルコクソンの〇〇検定も実行してみれば良い
    - tips)t分布は、サンプルサイズ$N$にのみ依存する分布なので扱いやすいので、t検定も使いやすかったと思われる
- t検定の適用例
    - ある集団Aの男性の身長の平均値が158cmであるとわかっている(すでに算出済)とする
    - サンプル200人の男性の身長の測定結果として、標本平均$\bar{x}=169$であった
    - 帰無仮説：「サンプルの母集団の男性の身長の母平均が158cm(ある集団Aの母平均と同じ)である」(μ=158)
        - t検定の帰無仮説は、μ=m の形(たいていは、m=0)を日本語で言い換えた文(お約束)
        - 当該200人が、ある集団Aのサンプルとみなしてよいか、とも解釈できる
    - この1つのサンプルがある集団Aから得られたものか、別のより背の高い集団から得られたものか(これは片側検定の文脈)を知りたい
    - 帰無仮説を棄却できるか判断するために、t統計量を計算する

        <img src="https://latex.codecogs.com/gif.latex?t&space;=&space;\frac{169&space;-&space;158}{\sqrt{\frac{2600&space;}{200}}}&space;\approx&space;3.05">

    - 有意水準(α)0.005 のt値は、2.576 ＜ 3.05=t統計量
        - 99.5%の信頼度で、帰無仮説を棄却できる
        - ある集団Aからサンプルを抽出したとしたら、まあまあ、ありえないことが起きたということ
        - 結果として、「サンプルの200人は、ある集団Aの標本とは言いがたい」と言える
- t検定の連語への適用
    - 「new companies」に関するt値を計算
    - 平均と分散を得るためのサンプル
        - 比率、頻度
    - 比率、頻度に対して、t検定を適用するための標準的な拡張方法
        - テキストコーパスをN個のバイグラムからなる長い列と考える
        - サンプルは、指標確率変数(indicator random variable)
            - 注目しているバイグラムが出現したら1、それ以外は、0とする確率変数
        - 最尤推定を用いて、「new」、「company」の確率を計算する
        - 「new」: 15,828回、「company」: 4,675回、全体のN: 14,307,668個のトークン

            <img src="https://latex.codecogs.com/gif.latex?P(new)&space;=&space;\frac{15828}{14307668}">
            <img src="https://latex.codecogs.com/gif.latex?P(companies)&space;=&space;\frac{4675}{14307668}">

        - 帰無仮説は、「「new」と「companies」の出現が独立」より、次式のように同時分布を計算
            <img src="https://latex.codecogs.com/gif.latex?P(new&space;companies)&space;=&space;P(new)&space;P(companies)&space;=&space;\frac{15828}{14307668}&space;\times&space;\frac{4675}{14307668}&space;\approx&space;3.615&space;\times&space;10^{-7}">

        - 帰無仮説が真であるならば、「new companies」の並びに対して1, それ以外に0 を付与して単語バイグラムランダムに生成する過程
            - 実質的に、$p = 3.615 \times 10^{-7}$ であるようなベルヌーイ試行(Bernoulli trial)
                - たぶん、np(1-p)＞5 (n=1)なので、正規分布に近似してもよいと言いたいっぽい
                - ref) https://ja.wikipedia.org/wiki/%E4%BA%8C%E9%A0%85%E5%88%86%E5%B8%83
                - 細かいことを言うと、独立性の条件を使う前に、正規性を言う必要がありそうだけど同時分布を計算できないから、仕方ないという感じだろうか
                - ref) https://ja.wikipedia.org/wiki/T%E6%A4%9C%E5%AE%9A
            - ベルヌーイ分布の平均と分散

                <img src="https://latex.codecogs.com/gif.latex?\mu&space;=&space;3.615&space;\times&space;10^{-7}">
                <img src="https://latex.codecogs.com/gif.latex?\sigma^2&space;=&space;p(1&space;-&space;p)&space;\approx&space;p&space;=&space;3.615&space;\times&space;10^{-7}">

            - ほとんどのバイグラムについて、$p$ が、小さい(ほぼ0)
        - コーパスをさらに調べることで、14,307,668個のバイグラムの中から、「new companies」が8回出現するとわかったとする
        - 標本平均を算出

            <img src="https://latex.codecogs.com/gif.latex?\bar{x}&space;=&space;\frac{8}{14307668}&space;\approx&space;5.591&space;\times&space;10^{-7}&space;">

        - t統計量を算出

            <img src="https://latex.codecogs.com/gif.latex?t&space;=&space;\frac{\bar{x}&space;-&space;\mu}{\sqrt{\frac{s^2&space;}{N}}}&space;=&space;\frac{5.591&space;\times&space;10^{-7}&space;-&space;3.615&space;\times&space;10^{-7}}{\sqrt{\frac{5.591&space;\times&space;10^{-7}}{14307668}}}&space;\approx&space;0.999932">

        - t値「0.999932」は、α=0.005に対する臨界値2.576以下
            - 帰無仮説を棄却できない
            - 帰無仮説; 「「new」と「companies」の出現が独立」
                - 「連語を構成しない」と同値であると解釈している点に注意
            - 「new companies」は、構成的と考えてもよい
            - 連語の地位に昇格させるために必要な新たな意味が付加されていない
            - t値が1にかなり近いのは、偶然らしい(練習問題5.5より)

    - 表5.6
        - コーパスにちょうど20回出現する10個のバイグラムt値
        - 上位5個: α=0.005で棄却できる → 良い連語の候補
        - 下位5個(残り): α=0.005で棄却できない(このコーパスでは、良い連語の候補とは言えなかった)
        - 頻度の方法では、10個に順位をつけられなかった
        - 少なくとも一方の単語の出現頻度に対して、高い割合でバイグラムが出現していれば、t値は大きくなる
            - この判断基準は、直感に合っている
        - いくつかのストップ語が含まれている点に注意
            - ストップ語を除くと、有意性がない例を見つけることが難しい(ほぼ有意差が出る)
            - コーパスで検証したほとんどのバイグラムは偶然より有意に多く出現する
            - バイグラムのうち、独立でない単語の組の割合は驚くほど高い
            - ランダムに単語を生成する場合に比べ、言語が規則的(予想がつかないことが起こらない)
- t検定やほかの統計的検定は、連語候補を順位付けする手法として有用
    - 有意水準自体は、さほど重要ではない
    - 本章では、有意水準については触れていない

### 5.3.2 差の仮説検定
(次回)

### 5.3.3 Pearson のカイ二乗検定
(次回)

## 5.4 相互情報量
(次回)

## 5.5 連語とは何か
(次回)

## 5.6 さらに学ぶために
(省略するかも)

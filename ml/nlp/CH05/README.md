UseMath: true
# 5章 連語
- 連語(Collocation)とは、二つ以上の単語からなる慣用に従った物事の言い方
- 連語とは単語を習慣的(habitual)、あるいは慣習的(customary)にどう配置するかを述べたもの
    - ex) 名詞句：strong tea, weapons of mass destruction
    - ex) 句動詞(phrasal verb)：make up
    - ex) 決まり文句(stock phrase)：the rich and powerful
- 連語の特長
    - 意味の構成性(compositionality)が限定的にしか成立しないこと
    - 構成性：その言語表現全体の意味が部分の意味から推測できること
    - 連語は、部分の意味を組み合わせたものに、通常何らかの意味が追加される点で、「完全に構成的」とは言えない
    - ex) strong tea
        - strong: この例では、「豊富な活性成分を持っている」の意
        - これは、「大きな物理的な力を持っている」という、strong 自体の基本的な意味と密接に関係しているが微妙に異なる
    - イディオム:非構成的な表現の最も極端な例
        - ex) kick the bucket: くたばる
        - ex) to hear it through the grapevine: 風のたよりに聞く
        - 間接的で歴史的な関係を持つだけ
        - バケツ(bucket)やブドウのつる(grapevine)の話はしていない
        - 連語の多くは、ここまで非構成的ではない
- 連語とかなり重なる概念
    - 用語(term)
    - 専門用語(technical term)
    - 専門用語句(terminological phrase)
    - これらは、専門用語抽出(terminology extraction) という処理)によって抽出される連語
- 連語の応用分野
    - 自然言語生成: 出力を自然にする(powerful tea, to take a decision という誤りを避ける)
    - 計算論的辞書編纂(へんさん)学: 辞書に掲載すべき重要な連語を自動選定
    - 構文解析: 解析結果が曖昧なとき自然な連語を選ぶ
    - コーパス言語研究: ex) 言語を通して文化的なステレオタイプの強化が起こるといった社会現象の研究
- 意味の文脈理論(Contextual Theory of Meaning)
    - 文脈の重要性を説いている
    - 架空の理想的な話者ではなく、どういう社会的な設定のもとで発話されているか
    - 孤立した文ではなく、会話、テキストにおいて、前後にどういう文が存在するか
    - 連語(周辺の単語の作る文脈の重要性)
    - ファースの有名な格言: 「単語は何を連れとしているかで特徴付けられる」
    - これらの文脈特徴は、構造主義言語学において、典型的な扱いによって簡単に失われる
- 言語の文脈的な見方
    - strong tea と powerful tea
    - 英語では、powerful tea と言わず、strong tea という
    - 構造的な性質からは、何もわからない
    - powerful: ヘロインのような薬を形容するが、タバコや紅茶、コーヒーを形容するのには使わない
- 連語を見つける手法
    - 頻度による選択(5.1)
    - 単語とその共起語の間の距離の平均と分散に基づく選択(5.2)
    - 仮説検定(5.3)
    - 相互情報量(5.4)
    - 「連語」とは何かという問題に立ち戻る
        - 提案されているさまざまな定義
        - あるフレーズが連語かどうかをテストする方法

## 5.1 頻度
- テキストコーパス中の連語を見つける一番簡単な方法は、単語の出現頻度を数えること
- 二つの単語が何回も一緒に出現する
    - 二単語の組が単なる組み合わせによる機能ではうまく説明できない特別な機能を持っている
- 表5.1: コーパス中のバイグラム(隣り合う2語)の高頻度順
    - 「New York」以外は、機能語(function word)の組
- 単純なヒューリスティックで相当改善可能
    - 句になりそうな瀕死のパターンだけを通すようにフィルタをかける

        **表5.2**

        | 品詞パターン | 例 |
        ---------------| ---------- |
        | A N | linear function
        | N N | regression coefficients
        | A A N | Gaussian random variable |
        | A N N | cumulative distribution function |
        | N A N | mean squared error |
        | N N N | class probability function |
        | N P N | degrees of freedom |

   - A: 形容詞、P: 前置詞、N: 名詞

- 表5.3: 表5.2 のフィルタを通したフレーズの高頻度順
   - 非構成的ではないフレーズは、３つのみ
       - last year, last week, first time(表5.3 には存在しない)
   - 「York City」: 実装誤りにより抽出された
- 表5.4: 'poworful w'、'strong w' のパターンの高頻度順
   - まあまあ、いい結果の例
   - strong challenge, powerful computers は、正解
   - powerful challenge, strong computers は、正しくなさそうという根拠になりうる
   - 頻度に基づく方法の限界: man など、いずれの形容詞(strong, powerful)とも一緒に使われる単語がある
   - より洗練された分析が必要
- 以上は、単純な定量的方法(頻度による選択方法)がうまくいくことを示している
   - 以降は、「ストップ語リスト」(stop word list)を使う
   - ストップ語リスト: 最も頻度の高い品詞タグが動詞、名詞、形容詞であるような単語以外を排除するためのリスト

## 5.2 平均と分散
- 頻度に基づく方法は、固定的なフレーズを見つけるのにうまくいく
- 実際の連語を構成する二つの単語は、もっと柔軟な関係で並んでいることが多い
- ex) (5.1) 動詞knock と最も頻繁にknock の項(argument)になるdoor / 「ドア(door)をノックする(knock)」という表現の例
    - a. she knocked on his door
    - b. they knocked at the door
    - c. 100 women knocked on Donaldson's door
    - d. a man knocked on the metal front door
    - knock と door の間に現れる単語は、多様
    - knock と door の間の距離(たぶん、語数)も一定ではない
    - 固定的なフレーズに対する手法ではうまくいかないはず
    - これらの単語の出現パターンを見ると、「叩く」という状況を表現する適切な動詞は、knockっぽい
    - hit, beat, rap ではないと判断するのに十分な規則性がある
- 固定的な連語と可変な連語
    - 簡単のため、本書のほとんどは、固定的な連語でしかもバイグラム(連続する2語) ... まじですかー。ちょっと残念。。
    - 連続する2語に適用可能な方法を、連続しない2語の組に拡張する方法は、容易に考えられる ... ま、まじ卍？！
        - 連語のための「窓」(１つの単語の前後3, 4語の幅)を定める
        - 定めた窓の中のすべての2単語の組を連語関係を持つ拡張されたバイグラム(のリスト)に加える
        - この拡張されたバイグラムの集合を使って以降の処理を行う
- 平均と分散に基づく方法
    - 定義自体において二つの単語がどういう間隔で出現するかというパターンを考慮している
    - 2語間の間隔のパターンが比較的、予測可能であるならば、knock ... door という必ずしも固定的でない連語が存在する証拠がえられたことになる
    - 連語とは何かというより深い議論はこの章の最後までおあずけ
    - コーパスにおいて、二つの間のオフセット(offset)(符号付き距離)の平均(mean)と分散(variance)を計算すること
    - ex) 5.1 の例で平均を説明
        $$ mean = \frac{1}{4}(3 + 3 + 5 + 5) = \frac{16}{4} = 4.0 $$
    - この計算では、Donaldson's が、Donaldson, ', s という三つの単語に分解されるとみなしている
    - もし、door が knocked の前に出現した場合は、オフセットは負の数になる
        - ex) the door that she knocked on の場合は、オフセットは、-3
    - 本節では、knocked を中心に、前後9語の窓内の位置に限定して分析を行う
    - 分散(↓の定義は、不偏分散)は、個々のオフセットがどれだけ平均からばらついているかという尺度

        $$ variance = s^2 = \frac{\sum_{i=1}^{n}(d_i - \bar{d})^2}{n-1} $$
    - 標本偏差(sample deviation) ... 不偏標準偏差のこと

        $$ s = \sqrt{s^2} $$
    - ex) 5.1 の例で標本偏差を説明

        $$ s = \sqrt{ \frac{1}{3}(3-4.0)^2 + (3-4.0)^2 + (5-4.0)^2 + (5-4.0)^2 } \approx 1.15 $$

    - 平均と標本偏差によって、コーパス中の二つの単語の距離の分布の特徴がわかる
        - 分布の特徴として、歪度(skewness/3次モーメント)、尖度(kurtosis/4次モーメント)もある
        - tips) 平均は、１次モーメント、分散は、2次モーメント
        - 標本偏差が小さい: 二つの単語がほとんど同じ相対位置で出現する
        - 標本偏差が0: 二つの単語が常に同じ相対位置で出現する
    - 図5.2 一番目の図の解説
        - 分布が示す情報は、ある語とほかの語との距離の分布のピークによっても説明できる
        - 「strong」の「opposition」からの距離の分布のピーク: -1
        - 「strong」の「opposition」に対する分散は小さい($s$ = 0.67)
        - 平均が -1.15 であるので、「strong」が通常は、-1 の位置に出現することを示している
        - -4 の位置が1回出現したという事実をノイズとして扱っている点に注意
        - サンプル数が増えたら-4 の出現数を無視できないかもしれない
    - 2つの単語の関係を見る場合、位置0 の出現数は常に0
    - 図5.2 二番目の図の解説
        - 「support」に対する「strong」の位置の頻度分布の例 ($s$ = 1.07)
        - 一番目の図と同じように分析する
    - 図5.2 三番目の図の解説
        - 「for」に対する「strong」の位置の頻度分布の例
        - 先の二つの例に比べると比較的、一様に分布している例(一様分布とは言いがたい)
        - つまり、分散(不偏標準偏差)が大きい例($s$ = 2.15)
    - 表5.5
        - 平均と分散による方法によって見つけられる連語の組の例
        - 真ん中の四つの例: 偏差が大きい →  二つの単語間に考慮すべき関係がないことを意味する
        - 一様分布に近い分布は、平均が0 に近い
        - 興味の対象は、少し離れた距離の頻度が大きいもの
- 以上で紹介した連語検出の方法は、Smadjaによるもの
    - 位置のヒストグラムにおいて、「平らな」ピークを除外
    - ex) 図5.2の strong / for の組み合わせで、-2 のところを除外
    - この除外が用語抽出において極めてうまくいくらしい(推定精度80%)
    - Smadja の連語概念は、ほかのものより制約がゆるい
    - knocked / door の組み合わせは、テキスト生成には有用かもしれないが専門用語としての連語にはならなさそう
- 分散による連語の検出は、間に挿入される要素や相対位置が可変であるような単語の組み合わせを見つけたい場合に適切な方法

## 5.3 仮設検定
- これまでの手法の問題
    - 頻度が高いこと、分散が小さいことは、偶然起こりうる
    - ex) new campanies: 特に連語ではなくても、これら二つの単語がまったく偶然に何回も出現しうる
    - 二つの単語が偶然よりも頻繁に一緒に出現するかどうかを知りたい ... 仮説検定を誘導するためのフリですね！
- 仮説検定
    - あることがらが偶然かどうかをみつもること
    - 統計学の古典的な問題
- 我々の問題での仮説検定
    - 帰無仮説(null hypothesis): $H_0$
        - 二つの単語の間に偶然以上の結びつきがないこと
    - $H_0$を定式化
    - $H_0$が真であると仮定して二つの単語の共起が起こる確率$p$を計算する
    - $p$が十分小さい場合、「$H_0$を棄却する」と表現する
        - (慣例的には、0.05などを基準とする; この基準を「有意水準」(significance level)と呼ぶ)
        - 有意水準($\alpha$と書くことが多い)は、0.05, 0.01, 0.005, 0.001 などとすることが多い
    - $p$が十分小さくない場合、「$H_0$が成り立ちうる」と表現する(棄却できないということ)
    - tips) 仮説検定では、本当は「帰無仮設を棄却したい」という文脈で行うケースが基本となっている(もちろん、そうでない場合もある)
- 仮説検定の定式化
    - 二つの単語が連語を形成しないという帰無仮説の定式化
    - 「連語を形成しない」を、「完全に独立」と考える/言い換える
    - 二つの単語$w^1 $、$w^2$の組について、その二語が互いに完全に独立に出現すると仮定する
    - この仮定のもとでは、二つの単語がこの順に連続して出現する確率は、次式で与えられる
        $$ P(w^1 w^2) = P(w^1) P(w^2) $$
    - このモデルは、過度に単純化したモデル / 経験的にも正しくない
        - 独立してないもので、「連語を形成しない」組もある点に注意(先の「new campanies」がその代表)
    - しかし、当面の帰無仮設としてこの独立性を採用する

### 5.3.1 t検定

### 5.3.2 差の仮説検定

### 5.3.3 Pearson のカイ二乗検定

## 5.4 相互情報量

## 5.5 連語とは何か

## 5.6 さらに学ぶために

